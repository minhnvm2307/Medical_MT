{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14072121,
          "sourceType": "datasetVersion",
          "datasetId": 8957524
        },
        {
          "sourceId": 286723860,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 694937,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 527000,
          "modelId": 541049
        },
        {
          "sourceId": 695177,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 527213,
          "modelId": 541256
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import kagglehub\n",
        "nguynvitcng21020173_vlsp_2025_data_path = kagglehub.dataset_download('nguynvitcng21020173/vlsp-2025-data')\n",
        "hung_vimedt5_path = kagglehub.model_download(\"phmquanghng23020084/vimedt5-300k/other/default\")\n",
        "# minhnvm2307_vitmedt5_finetuned_transformers_default_2_path = kagglehub.model_download('minhnvm2307/vitmedt5-finetuned/Transformers/default/2')\n",
        "# minhnvm2307_qwen2_5_vlsp_finetuned_transformers_default_1_path = kagglehub.model_download('minhnvm2307/qwen2-5-vlsp-finetuned/Transformers/default/1')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "FBnKFgBQ0yBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "129c3143-4cdf-4e79-c6c1-21ae50e637f6"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'vlsp-2025-data' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/vitmedt5\n",
        "!cp -r /root/.cache/kagglehub/models/phmquanghng23020084/vimedt5-300k/other/default/1/envit5_final_model_more/* /content/vitmedt5\n",
        "# !cp -r /root/.cache/kagglehub/datasets/nguynvitcng21020173/vlsp-2025-data/ /content/"
      ],
      "metadata": {
        "id": "tP0zQPbN1yhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db816aab-1a5a-4123-82ef-9839bbcf6914"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/vitmedt5’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sacrebleu sacremoses rouge-score"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-21T19:13:11.75893Z",
          "iopub.execute_input": "2025-12-21T19:13:11.759915Z",
          "iopub.status.idle": "2025-12-21T19:13:17.414795Z",
          "shell.execute_reply.started": "2025-12-21T19:13:11.759887Z",
          "shell.execute_reply": "2025-12-21T19:13:17.413566Z"
        },
        "id": "jR3_cQou0yB1"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import sacrebleu\n",
        "import math\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import gc"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "IA8pG1fL0yB0"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import ( AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, )\n",
        "\n",
        "model_name = \"/content/vitmedt5\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to('cuda')\n",
        "\n",
        "print(type(model))\n",
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-21T19:12:28.213422Z",
          "iopub.execute_input": "2025-12-21T19:12:28.213714Z",
          "iopub.status.idle": "2025-12-21T19:13:11.756533Z",
          "shell.execute_reply.started": "2025-12-21T19:12:28.213697Z",
          "shell.execute_reply": "2025-12-21T19:13:11.752939Z"
        },
        "id": "LRQviBcH0yB0",
        "outputId": "61b8548b-98b3-41dd-e550-236a57e3f28c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(50048, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(50048, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(50048, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50048, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data (quiet)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)  # thêm để METEOR ổn định hơn\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "class TranslationEvaluator:\n",
        "    def __init__(self, src_path, tgt_path, model, tokenizer, device=\"cuda\"):\n",
        "        self.src_path = src_path\n",
        "        self.tgt_path = tgt_path\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.model = model.to(device)\n",
        "        self.rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.batch_size = 64  # Tối ưu cho 2 GPU\n",
        "\n",
        "        self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        with open(self.src_path, encoding=\"utf-8\") as f:\n",
        "            self.src_lines = [l.strip() for l in f.readlines()]\n",
        "        with open(self.tgt_path, encoding=\"utf-8\") as f:\n",
        "            self.tgt_lines = [l.strip() for l in f.readlines()]\n",
        "\n",
        "        min_len = min(len(self.src_lines), len(self.tgt_lines))\n",
        "        self.src_lines = self.src_lines[:min_len]\n",
        "        self.tgt_lines = self.tgt_lines[:min_len]\n",
        "\n",
        "    def translate_batch(self, texts, max_len=128):\n",
        "        outputs = []\n",
        "        batch_size = self.batch_size\n",
        "        total = (len(texts) + batch_size - 1) // batch_size\n",
        "\n",
        "        self.model.eval()\n",
        "        for i in tqdm(range(0, len(texts), batch_size), total=total, desc=\"Translating\", leave=False):\n",
        "            batch = texts[i:i + batch_size]\n",
        "            inputs = self.tokenizer(batch, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                if isinstance(self.model, nn.DataParallel):\n",
        "                    generated = self.model.module.generate(**inputs, max_length=max_len, num_beams=5, early_stopping=True)\n",
        "                else:\n",
        "                    generated = self.model.generate(**inputs, max_length=max_len, num_beams=5, early_stopping=True)\n",
        "\n",
        "            decoded = self.tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "            outputs.extend(decoded)\n",
        "\n",
        "            # Giảm tần suất clear cache để nhanh hơn\n",
        "            if i % (batch_size * 20) == 0 and i > 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def evaluate_direction(self, src_lines, tgt_lines, direction):\n",
        "        predictions = self.translate_batch(src_lines)\n",
        "\n",
        "        # Tính các metric nhanh\n",
        "        bleu = sacrebleu.corpus_bleu(predictions, [tgt_lines]).score\n",
        "        ter = sacrebleu.corpus_ter(predictions, [tgt_lines]).score\n",
        "\n",
        "        # METEOR và ROUGE-L (phải loop, nhưng có tqdm)\n",
        "        meteor_scores = [meteor_score([word_tokenize(ref)], word_tokenize(pred))\n",
        "                         for pred, ref in tqdm(zip(predictions, tgt_lines), total=len(predictions), desc=\"METEOR\", leave=False)]\n",
        "        meteor = sum(meteor_scores) / len(meteor_scores) * 100\n",
        "\n",
        "        rouge_scores = [self.rouge.score(ref, pred)['rougeL'].fmeasure * 100\n",
        "                        for pred, ref in tqdm(zip(predictions, tgt_lines), total=len(predictions), desc=\"ROUGE-L\", leave=False)]\n",
        "        rouge_l = sum(rouge_scores) / len(rouge_scores)\n",
        "\n",
        "        # In bảng kết quả\n",
        "        print(f\"\\n{direction} RESULTS:\")\n",
        "        print(f\"BLEU:    {bleu:.2f}\")\n",
        "        print(f\"TER:     {ter:.2f}\")\n",
        "        print(f\"METEOR:  {meteor:.2f}\")\n",
        "        print(f\"ROUGE-L: {rouge_l:.2f}\")\n",
        "\n",
        "        # In 3 ví dụ\n",
        "        print(f\"\\nSAMPLE TRANSLATIONS ({direction}):\")\n",
        "        for i in range(min(3, len(predictions))):\n",
        "            print(f\"\\n[Sample {i+1}]\")\n",
        "            print(f\"SRC:  {src_lines[i]}\")\n",
        "            print(f\"PRED: {predictions[i]}\")\n",
        "            print(f\"REF:  {tgt_lines[i]}\")\n",
        "\n",
        "        return {\n",
        "            'bleu': bleu,\n",
        "            'ter': ter,\n",
        "            'meteor': meteor,\n",
        "            'rouge_l': rouge_l,\n",
        "            'predictions': predictions\n",
        "        }\n",
        "\n",
        "    def full_evaluation(self, direction_name=\"SRC->TGT\"):\n",
        "        return self.evaluate_direction(self.src_lines, self.tgt_lines, direction_name)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-21T19:13:17.416863Z",
          "iopub.execute_input": "2025-12-21T19:13:17.417338Z",
          "iopub.status.idle": "2025-12-21T19:13:18.394233Z",
          "shell.execute_reply.started": "2025-12-21T19:13:17.417264Z",
          "shell.execute_reply": "2025-12-21T19:13:18.393662Z"
        },
        "id": "T9Xtm4D30yB2"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "src_path = \"/content/vlsp-2025-data/versions/1/public_test.en.txt\"\n",
        "tgt_path = \"/content/vlsp-2025-data/versions/1/public_test.vi.txt\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-21T19:13:18.395826Z",
          "iopub.execute_input": "2025-12-21T19:13:18.396667Z",
          "iopub.status.idle": "2025-12-21T19:13:19.800921Z",
          "shell.execute_reply.started": "2025-12-21T19:13:18.396646Z",
          "shell.execute_reply": "2025-12-21T19:13:19.800041Z"
        },
        "id": "JvUWo5dp0yB3"
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm chạy đánh giá 2 chiều (tối ưu, gọn)\n",
        "def run_bidirectional_evaluation(en_file_path, vi_file_path, model, tokenizer, device=\"cuda\"):\n",
        "    results = {}\n",
        "\n",
        "    # EN -> VI\n",
        "    evaluator = TranslationEvaluator(en_file_path, vi_file_path, model, tokenizer, device)\n",
        "    results['en_to_vi'] = evaluator.full_evaluation(\"EN->VI\")\n",
        "    del evaluator\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # VI -> EN\n",
        "    evaluator = TranslationEvaluator(vi_file_path, en_file_path, model, tokenizer, device)\n",
        "    results['vi_to_en'] = evaluator.full_evaluation(\"VI->EN\")\n",
        "    del evaluator\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-21T19:13:19.802567Z",
          "iopub.execute_input": "2025-12-21T19:13:19.80286Z",
          "iopub.status.idle": "2025-12-21T19:13:20.838799Z",
          "shell.execute_reply.started": "2025-12-21T19:13:19.802831Z",
          "shell.execute_reply": "2025-12-21T19:13:20.837861Z"
        },
        "id": "560zarGe0yB3"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "# Chạy đánh giá\n",
        "results = run_bidirectional_evaluation(\n",
        "    en_file_path=src_path,   # Thay bằng đường dẫn thực\n",
        "    vi_file_path=tgt_path, # Thay bằng đường dẫn thực\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "\n",
        "# In kết quả cuối (nếu cần truy xuất)\n",
        "print(\"\\nFinal BLEU scores:\")\n",
        "print(f\"EN->VI: {results['en_to_vi']['bleu']:.2f}\")\n",
        "print(f\"VI->EN: {results['vi_to_en']['bleu']:.2f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-21T19:13:59.614994Z",
          "iopub.execute_input": "2025-12-21T19:13:59.615673Z",
          "iopub.status.idle": "2025-12-21T19:42:22.960309Z",
          "shell.execute_reply.started": "2025-12-21T19:13:59.615647Z",
          "shell.execute_reply": "2025-12-21T19:42:22.959664Z"
        },
        "id": "Jrgc4TsS0yB4",
        "outputId": "cc459363-672f-4c43-ad5d-7b1e26c1ea66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  43%|████▎     | 20/47 [04:32<06:12, 13.81s/it]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ScMKwwQp0yB5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}